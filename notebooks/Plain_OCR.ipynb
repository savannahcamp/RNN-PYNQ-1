{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM on Pynq\n",
    "This notebook covers how to use the FPGA-accelerated BiLSTM implementation on PYNQ to perform optical character recognition (OCR). The BiLSTM has been trained on a simple dataset (here called *plain*) of a few hundreds sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load a line of text\n",
    "Load a line of text that we are going to use as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAAArCAYAAACTrfvrAAAILUlEQVR4nO2d7Y7cKgxAk6rv/8q5v+Zumg3gL8Aw50grdXcyjjG2MYTQ87qu6wAAAAAA2IQ/sxUAAAAAAIiEAhcAAAAAtuLvbAUAADJynudxHMfBLi6A70STA3bIF582HEefdvSW/4QCF6rsELQAGu5JGNbn2Z/fmMtGFxY7IMkDO+WK0W05z7O7L25f4GqSG4nwh50CF0DDdV3/+P+IRAzQA/I4SHnmvRH3683We3AJbgCA7+abJyff3PYRYF8d13X9/zOCrQtcrRFx1h+wBQDA+pDLbUiLMeybl60LXAAAAAD4PihwAQBAzHmebP8CgPRQ4H4hDFAAYIG8AQCrQIH7ZTBAAYAFcgcArMT2x4TBDwxQuSn1j+clhoij7970Gi2n5ru85NGfN/trz8ju4d8RRB4PmfHccE/ejzwizysr+hhPydnA3v6M8PnI3De7BpCex1zq65b+T5nnVbhLyRlHnyvrdRCtDpoDsVc6PNsSJFonmxW0Gkp95tFHKlNqZ6se0fIkcjT/w8/9emseKdk32mdq+kXnpNlyIu5Vu9+bLaMmTVIsA7vWtz1yvGjaNyPue8loybHaReOf1qIxqv0WWb8KwQHxKL2HpwhvFrgRlXO0Y9d00AZrRNFqHeBmFsSWPpEOTBJZGl2kcjR4Z64RgdiS4Z1QRsrTJEPJAGNdIfF+bqXXoCW1q1SOp280WCeALX1GFbo9+lMzWe6V77VFS0uXqDbV4tKyimfxG09+trZXiyX/vt2vR10zIg4jaqyazD+1Cz9/k3Te57qIJfBSZ2RZJX3TI4tuJUo6f34k3JOW5nstGSV5kY9TWrq22tRj0JIkHY1NLPJaSHw9csY9+vvWe1pWc6xPhzSf9bJHLX+UkAxm0Ss4Wixx//z787uj2tTyJ22OfubmpyyLXm94VxulMkblhloxZvWvuwzJ36PyThaiaqx/CtyagFYxUrvO2hkl+ZrrM7KKk73RM/H1RjoIaAYGTRzc8SSdSDuWJrXH0c4HUjm9GRVPz360TvJ6s5pOWSYpFj2iJpIrMGrsleZGq40lNUqPiXcpXzzt2Cu/SxZ5smL1g+YpClmT+Gx2KLS19FwVLH02065WXaLjJWLFoyRv9ipHTYf7d2bHV+RqveceGh+cmbe923dm9XfPAmRW4aKRN2uy2PM+o+8xK+5m58iM/CpwPZ1DIVxmdAKJxrtSKw2+0Y8nZ8iM3sZjQbKacN929PbTW+csRU8EUb62ok1Wy3kRT6Uy9UvUUzZLXtfawZIjIp64efDmtZZsa/71+mBvHx6RF9IdE7ZSMryu61dBsJL+s8iU/KPp5QNPX1uBN5299ll5otjS2bMyuKI9WvSMpUhGx2X0/Xo+Iv/Ii9z+sTMz32foLe/JiLyVrsBtsdogDzJKBdzsJLdCYdlLv1621xSpJfvvVNRFrehnsYe1PSvGmmR7Te26jETsPy0VzSvZQUpPv93RXiNZpsDNmvgkq7g7B7eFnV/M2KENkdSSv7QoqxW5n89XRPJ4t/SySutx8ao2yYK3aBm5lzWzvCeZJmLZwU5+0v9Xvff9JrNfnPhmsk4wsoGdflOLW+l+slrcr2bzt5ymzW2t6zPZJJMuu5HVthEx/+1gIz9pC9yVClvJix+Z9Zewuv4wn9ag1/v7GYheZV2lyIXvxOOfO/sv4+kYXAWudsVBSpZHbRnedt8RbLIGPfeVeU9rWXGA6JXXKHLHsaLfaejhLztMTGuMOFEGbLgK3B6dJBkEMu5velvFxYlhBCseHXUc8YepZ273iCN3shRfvY5Ey0hmn8vGCv05g7tdVsppK5B2i0KN1Tp9h8BezeY96H2qgIZeR05Z5cx62rFDbGmp2Wlle4zKMdozRKNsmjWHeooq7dm4WltmtdlIpP7aOrmj95nEGRm2RUHC6gZdeXBpMWu1bbZP9HpkN1uP0hOGN92se+UkTzFaqxez+39FMuahnftRWzB7GbHKJ22TZetBzT+t+Wemf3mK9tIpKbXvlD6T6CGRsxPDVnDZpyLjE6zZ2j4jifa2geb+vY/j0bRVkxTfzqOMiMWnn1rtE1kcZCzsNHhXzkajLWK8Pj4KawFSWs30xogETeGimdi22tQDSy7LFPvSvrAUxm8/NVnSOKwtUmTAqse0PbjWFTztIxEPEY9MrS/XWe+vYbTz1hKXNnCjmBnY0iJXmhRbx/K0HmFFy7l/r4VVRpYErKXk76Xr7r+//fv5nR604ld6/Rs9J5Ot+1n0kMTIyAny/d6l35/XSrG2qUdfaxeARo+ptfto2t37JVRJ7hlB7xx2Xo/WawYvaVLTXOtt2F2mRj/L9RI5ngLXen/tPd7u5bVdxFuzPQa6iEmLRJ633z0yIwrKCDk1H4r0l1F+4slt0na0/Kl1L+3kQ4s0f0i+89beWaucT0bHmhXPeOkZf61jQUSBLNWjJMOT+0borJEZMc689U+mFXEPzQL3OPxFa8S1z+94BpUIHWtYnWRmgRttO28iyPJCl7Uds5JYTWbkNoIIWask0VY8eyfvrdizFsu98PhVVLx4iI61rG3yFC69J+6r+Qysya8CNwvSgTDjjMOr04giIKPdRjByxQgAAADm8He2AiWkhUfWAsWjV+1RZRRZ7TYSbAAAALAnS56Dm5lVX3oBAAAA2AUK3MSwwggAAACghwI3kKh9redZPkAbAAAAAOqk3YObneeLYJFbEyhuAQAAAOywgmugdng0xek6sF8aAABgTyhwA6G4BQAAAJhP2nNwAQAAAAAssIILAAAAAFtBgQsAAAAAW/Efty7l7gOovq0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=696x43 at 0x29139C90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "im = Image.open('/home/xilinx/jupyter_notebooks/rnn/Plain_images/010077.bin.png')\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hardware accelerated OCR\n",
    "For this set of experiments, we trained the same BiLSTM architecture on the same dataset at different precisions. In the following cells, we show how performances scale with respect to the chosen precision: lowering precision allows to better parallelize our FPGA implementation of the model, thus reducing the overall inference time, at a negligible-to-none cost in terms of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1\n",
    "**Weights**: *4 bits*\n",
    "**Activations**: *8 bits*\n",
    "**Parallelism**: *1x*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W4A8 HW OCRed text: mally, the process has to be described in\n",
      "W4A8 HW MOps/s: 16481.11213485034\n",
      "W4A8 HW inference time [ms]: 11.089892387390137\n"
     ]
    }
   ],
   "source": [
    "W4A8_hw_ocr = rnn.PynqPlainOCR(network=\"W4A8\", runtime=rnn.RUNTIME_HW)\n",
    "W4A8_hw_result = W4A8_hw_ocr.inference(im)\n",
    "W4A8_hw_mops_per_s, W4A8_hw_ms_inference_time, W4A8_hw_recognized_text = W4A8_hw_result\n",
    "W4A8_hw_ocr.cleanup()\n",
    "\n",
    "print(\"W4A8 HW OCRed text: {}\".format(W4A8_hw_recognized_text))\n",
    "print(\"W4A8 HW MOps/s: {}\".format(W4A8_hw_mops_per_s))\n",
    "print(\"W4A8 HW inference time [ms]: {}\".format(W4A8_hw_ms_inference_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2\n",
    "**Weights**: *4 bits*\n",
    "**Activations**: *4 bits*\n",
    "**Parallelism**: *4x*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W4A4 HW OCRed text: mally, the process has to be described in\n",
      "W4A4 HW MOps/s: 61789.578061051216\n",
      "W4A4 HW inference time [ms]: 2.958003044128418\n"
     ]
    }
   ],
   "source": [
    "W4A4_hw_ocr = rnn.PynqPlainOCR(network=\"W4A4\", runtime=rnn.RUNTIME_HW)\n",
    "W4A4_hw_result = W4A4_hw_ocr.inference(im)\n",
    "W4A4_hw_mops_per_s, W4A4_hw_ms_inference_time, W4A4_hw_recognized_text = W4A4_hw_result\n",
    "W4A4_hw_ocr.cleanup()\n",
    "\n",
    "print(\"W4A4 HW OCRed text: {}\".format(W4A4_hw_recognized_text))\n",
    "print(\"W4A4 HW MOps/s: {}\".format(W4A4_hw_mops_per_s))\n",
    "print(\"W4A4 HW inference time [ms]: {}\".format(W4A4_hw_ms_inference_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3\n",
    "**Weights**: *2 bits*\n",
    "**Activations**: *4 bits*\n",
    "**Parallelism**: *4x*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2A4 HW OCRed text: mally, the process has to be described in\n",
      "W2A4 HW MOps/s: 61606.69599659392\n",
      "W2A4 HW inference time [ms]: 2.9667840003967285\n"
     ]
    }
   ],
   "source": [
    "W2A4_hw_ocr = rnn.PynqPlainOCR(network=\"W2A4\", runtime=rnn.RUNTIME_HW)\n",
    "W2A4_hw_result = W2A4_hw_ocr.inference(im)\n",
    "W2A4_hw_mops_per_s, W2A4_hw_ms_inference_time, W2A4_hw_recognized_text = W2A4_hw_result\n",
    "W2A4_hw_ocr.cleanup()\n",
    "\n",
    "print(\"W2A4 HW OCRed text: {}\".format(W2A4_hw_recognized_text))\n",
    "print(\"W2A4 HW MOps/s: {}\".format(W2A4_hw_mops_per_s))\n",
    "print(\"W2A4 HW inference time [ms]: {}\".format(W2A4_hw_ms_inference_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 4\n",
    "**Weights**: *2 bits* **Activations**: *2 bits* **Parallelism**: *8x*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2A2 HW OCRed text: mally, the process has to be described in\n",
      "W2A2 HW MOps/s: 141296.245179383\n",
      "W2A2 HW inference time [ms]: 1.2935500144958496\n"
     ]
    }
   ],
   "source": [
    "W2A2_hw_ocr = rnn.PynqPlainOCR(network=\"W2A2\", runtime=rnn.RUNTIME_HW)\n",
    "W2A2_hw_result = W2A2_hw_ocr.inference(im)\n",
    "W2A2_hw_mops_per_s, W2A2_hw_ms_inference_time, W2A2_hw_recognized_text = W2A2_hw_result\n",
    "W2A2_hw_ocr.cleanup()\n",
    "\n",
    "print(\"W2A2 HW OCRed text: {}\".format(W2A2_hw_recognized_text))\n",
    "print(\"W2A2 HW MOps/s: {}\".format(W2A2_hw_mops_per_s))\n",
    "print(\"W2A2 HW inference time [ms]: {}\".format(W2A2_hw_ms_inference_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "Here is a comparison of the inference time for the hardware accelerated implementation at different precisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26770f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "height = [W2A2_hw_ms_inference_time, \n",
    "          W2A4_hw_ms_inference_time, \n",
    "          W4A4_hw_ms_inference_time, \n",
    "          W4A8_hw_ms_inference_time]\n",
    "bars = ('W2A2', 'W2A4', 'W4A4', 'W4A8')\n",
    "y_pos = np.arange(len(bars))\n",
    "plt.bar(y_pos, height)\n",
    "plt.xticks(y_pos, bars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Software accelerated OCR\n",
    "For the sake of comparison, we show here a software implementation for a given (W4A4) precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W4A4 SW OCRed text: mally, the process has to be described in\n",
      "W4A4 SW MOps/s: 2.4391782189015494\n",
      "W4A4 SW inference time [ms]: 74932.515625\n"
     ]
    }
   ],
   "source": [
    "W4A4_sw_ocr = rnn.PynqPlainOCR(network=\"W4A4\", runtime=rnn.RUNTIME_SW)\n",
    "W4A4_sw_result = W4A4_sw_ocr.inference(im)\n",
    "W4A4_sw_mops_per_s, W4A4_sw_ms_inference_time, W4A4_sw_recognized_text = W4A4_sw_result\n",
    "W4A4_sw_ocr.cleanup()\n",
    "\n",
    "print(\"W4A4 SW OCRed text: {}\".format(W4A4_sw_recognized_text))\n",
    "print(\"W4A4 SW MOps/s: {}\".format(W4A4_sw_mops_per_s))\n",
    "print(\"W4A4 SW inference time [ms]: {}\".format(W4A4_sw_ms_inference_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
